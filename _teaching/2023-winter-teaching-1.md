---
title: "Statistical Data Analysis"
collection: teaching
type: "Undergraduate course"
permalink: /teaching/2023-winter-teaching-1
venue: "University of Potsdam, Department of Data Science"
date: 2023-10-01
location: "Potsdam, Germany"
---

 Beginning with the foundational elements of probability theory, the curriculum delves into the core concepts of learning, various regression models, and the nuanced differences between batch and sequential processing. Advanced topics such as Support Vector Machines, VC Dimension, and Gaussian Processes are seamlessly integrated, ensuring a well-rounded understanding. Techniques like Principal Component Analysis, Autoencoders, and Generative Adversarial Networks highlight the course's depth in the domain. I have the opportunity to lead the exercise sessions and even will jump in for a couple of lectures. While we dive deep into the theory, we're all about hands-on application. The course is jam-packed with exercises to ensure you're not just learning, but actively applying these concepts.


Course Content
======

* Recap foundations of probability theory: Revisiting the core principles of probability, including events, outcomes, and probability distributions.

* Introduction to the concept of learning: Exploring how machines can infer patterns and make predictions based on data.

* Linear regression: A statistical approach to modeling the relationship between a dependent variable and one or more independent variables.

* Batch vs Sequential: Comparing the two training methods: processing all data at once versus processing one data point at a time.

* Generalized Linear Regression: Expanding traditional linear regression to accommodate non-normal distributions and non-linear link functions.

* Nonlinear Optimization's - Stochastic gradient descent: An optimization technique that adjusts parameters iteratively to minimize the error, suitable for non-linear functions.

* Parametrization by means of Neural networks: Using neural network architectures to parameterize complex functions and capture intricate data patterns.

* Classification: Determining to which of a set of categories a new observation belongs, based on a training set of data.

* Support Vector Machines: A supervised learning model used for classification and regression analysis, focusing on maximizing the margin between classes.

* VC Dimension: A measure of the capacity of a statistical classification model, indicating the complexity of the model.

* Clustering: Grouping data points in such a way that points in the same group are more similar to each other than to those in other groups.

* Random Forest models: An ensemble learning method, aggregating multiple decision trees for classification, regression, and other tasks.

* Principle Component Analysis: A dimensionality reduction technique that transforms features into orthogonal components, capturing the most variance.

* Autoencoders: Neural networks used for unsupervised learning, compressing data into a lower-dimensional form and then reconstructing it.

* Gaussian Processes: A collection of random variables, any finite number of which have a joint Gaussian distribution.

* Optimal transport: A mathematical theory describing how to transform one distribution into another in the most efficient way.

* Generative adversarial networks: A class of machine learning models where two neural networks, the generator, and the discriminator, are trained together.

* Score functions: Functions used to evaluate the quality or performance of a model or solution in a specific context.
